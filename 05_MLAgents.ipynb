{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/migolan/HF-DRLC/blob/main/05_MLAgents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "\n",
        "This notebook is based on https://huggingface.co/learn/deep-rl-course/unit5/hands-on.\n",
        "\n",
        "* [Pyramids environment](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Learning-Environment-Examples.md#pyramids)\n",
        "* SnowballTarget environment\n",
        "* [ML-Agents library](https://github.com/Unity-Technologies/ml-agents)\n",
        "  * [Training Configuration File](https://github.com/Unity-Technologies/ml-agents/blob/release_20_docs/docs/Training-Configuration-File.md)\n",
        "* PPO agent\n",
        "* [Random Network Distillation](https://medium.com/data-from-the-trenches/curiosity-driven-learning-through-random-network-distillation-488ffd8e5938)"
      ],
      "metadata": {
        "id": "9_Y9Vsq-9_3M"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an3ByrXYQ4iK"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install virtualenv\n",
        "!virtualenv myenv\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!source /usr/local/bin/activate\n",
        "!conda install -q -y --prefix /usr/local python=3.10.12 ujson\n",
        "!export PYTHONPATH=/usr/local/lib/python3.10/site-packages/\n",
        "!export CONDA_PREFIX=/usr/local/envs/myenv"
      ],
      "metadata": {
        "id": "j9suaHUqyj4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WNoL04M7rTa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone --depth 1 https://github.com/Unity-Technologies/ml-agents\n",
        "%cd ml-agents\n",
        "!pip3 install -e ./ml-agents-envs\n",
        "!pip3 install -e ./ml-agents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SnowballTarget environment"
      ],
      "metadata": {
        "id": "R5_7Ptd_kEcG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRY5ufKUKfhI"
      },
      "source": [
        "## Install environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9Ls6_6eOKiA"
      },
      "outputs": [],
      "source": [
        "!mkdir ./training-envs-executables\n",
        "!mkdir ./training-envs-executables/linux\n",
        "!wget \"https://github.com/huggingface/Snowball-Target/raw/main/SnowballTarget.zip\" -O ./training-envs-executables/linux/SnowballTarget.zip\n",
        "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/SnowballTarget.zip\n",
        "!chmod -R 755 ./training-envs-executables/linux/SnowballTarget"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the SnowballTarget config file\n",
        "`./content/ml-agents/config/ppo/SnowballTarget.yaml`:\n",
        "\n",
        "```\n",
        "behaviors:\n",
        "  SnowballTarget:\n",
        "    trainer_type: ppo\n",
        "    summary_freq: 10000\n",
        "    keep_checkpoints: 10\n",
        "    checkpoint_interval: 50000\n",
        "    max_steps: 200000\n",
        "    time_horizon: 64\n",
        "    threaded: false\n",
        "    hyperparameters:\n",
        "      learning_rate: 0.0003\n",
        "      learning_rate_schedule: linear\n",
        "      batch_size: 128\n",
        "      buffer_size: 2048\n",
        "      beta: 0.005\n",
        "      epsilon: 0.2\n",
        "      lambd: 0.95\n",
        "      num_epoch: 3\n",
        "    network_settings:\n",
        "      normalize: false\n",
        "      hidden_units: 256\n",
        "      num_layers: 2\n",
        "      vis_encode_type: simple\n",
        "    reward_signals:\n",
        "      extrinsic:\n",
        "        gamma: 0.99\n",
        "        strength: 1.0\n",
        "```"
      ],
      "metadata": {
        "id": "NAuEq32Mwvtz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9fI555bO12v"
      },
      "source": [
        "## Train the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS-Yh1UdHfzy"
      },
      "outputs": [],
      "source": [
        "!mlagents-learn ./config/ppo/SnowballTarget.yaml --env=./training-envs-executables/linux/SnowballTarget/SnowballTarget --run-id=\"SnowballTarget1\" --no-graphics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vue94AzPy1t"
      },
      "source": [
        "## Push the agent to the HF Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKt2vsYoK56o"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-push-to-hf --run-id=\"SnowballTarget1\" --local-dir=\"./results/SnowballTarget1\" --repo-id=\"migolan/ppo-SnowballTarget\" --commit-message=\"First Push\""
      ],
      "metadata": {
        "id": "kAFzVB7OYj_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Watch the agent playing\n",
        "https://huggingface.co/spaces/ThomasSimonini/ML-Agents-SnowballTarget"
      ],
      "metadata": {
        "id": "VMc4oOsE0QiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pyramids environment"
      ],
      "metadata": {
        "id": "rVMwRi4y_tmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://huggingface.co/spaces/unity/ML-Agents-Pyramids/resolve/main/Pyramids.zip\" -O ./training-envs-executables/linux/Pyramids.zip\n",
        "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/Pyramids.zip\n",
        "!chmod -R 755 ./training-envs-executables/linux/Pyramids/Pyramids"
      ],
      "metadata": {
        "id": "eWh8Pl3sjZY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Modify the PyramidsRND config file\n",
        "- The Pyramids environment is part of Unity, so the PyramidsRND config file already exists in `./content/ml-agents/config/ppo/PyramidsRND.yaml`.\n",
        "- RND stands for *random network distillation* - a way to generate curiosity rewards: https://medium.com/data-from-the-trenches/curiosity-driven-learning-through-random-network-distillation-488ffd8e5938.\n"
      ],
      "metadata": {
        "id": "fqceIATXAgih"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXi4-IaHBhqD"
      },
      "outputs": [],
      "source": [
        "!mlagents-learn ./config/ppo/PyramidsRND.yaml --env=./training-envs-executables/linux/Pyramids/Pyramids --run-id=\"Pyramids Training\" --no-graphics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txonKxuSByut"
      },
      "source": [
        "## Push the agent to the HF Hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-push-to-hf  --run-id=\"Pyramids Training\" --local-dir=\"./results/Pyramids Training\"  --repo-id=\"migolan/ppo-Pyramids\"  --commit-message=\"First Push\""
      ],
      "metadata": {
        "id": "yiEQbv7rB4mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Watch the agent playing\n",
        "\n",
        "https://huggingface.co/spaces/unity/ML-Agents-Pyramids"
      ],
      "metadata": {
        "id": "7aZfgxo-CDeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional challenges\n",
        "* [Other MLAgents environments](https://github.com/Unity-Technologies/ml-agents/blob/develop/docs/Learning-Environment-Examples.md)\n",
        "- [Worm](https://huggingface.co/spaces/unity/ML-Agents-Worm) demo where you teach a **worm to crawl**.\n",
        "- [Walker](https://huggingface.co/spaces/unity/ML-Agents-Walker) demo where you teach an agent **to walk towards a goal**."
      ],
      "metadata": {
        "id": "hGG_oq2n0wjB"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}